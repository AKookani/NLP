{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKookani/NLP/blob/main/HW_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU9OP6qZBPkB"
      },
      "source": [
        "# TA: Mohammad Erfan Zare\n",
        "# Question topics: LLM & RAG\n",
        "# FALL 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XROW1IcYBPkK"
      },
      "source": [
        "Install the required libraries: `transformers`, `datasets`, and `faiss`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZptqFSE0BPkO",
        "outputId": "a02c06a0-ed70-4c50-d96f-56fbf7d53852",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, faiss-cpu, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 faiss-cpu-1.9.0.post1 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkNiWGdNBPkR"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AhNHZb8WBPkT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline, AutoModel\n",
        "from datasets import load_dataset\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83XrDXQ3BPkU"
      },
      "source": [
        "1. Use the [**`wikipedia`** dataset](https://huggingface.co/datasets/wikipedia) from the Hugging Face library.\n",
        "2. Extract a subset of articles and prepare it as a knowledge base for retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzCRA5wFBPkW",
        "outputId": "fe0202ad-a807-4ecb-80f4-d1c956d56252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "data = load_dataset(\"wikipedia\", \"20220301.simple\", split=\"train[:1%]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbmcVGAGBPkX"
      },
      "source": [
        "# Task1: preprocess on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o-bN8ELeBPkY"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer for the chosen model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Function to preprocess and tokenize the articles\n",
        "def preprocess_article(batch):\n",
        "    # Access the 'text' feature directly\n",
        "    texts = [text.strip() for text in batch['text']]\n",
        "    tokens = tokenizer(texts, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "    # Convert tensor outputs to lists for compatibility with datasets\n",
        "    return {\"input_ids\": tokens['input_ids'].tolist(), \"attention_mask\": tokens['attention_mask'].tolist()}\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "tokenized_data = data.map(preprocess_article, batched=True, batch_size=16)\n",
        "\n",
        "# Now tokenized_data contains tokenized representations of the articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZRL4_dABPkb"
      },
      "source": [
        "# Task2: Index Creation for Retrieval\n",
        "1. Use **FAISS** to create an index of the articles for efficient similarity search.\n",
        "2. Extract embeddings using a pretrained transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c0ygYPixBPkd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cb350fa9bcb8461dbe8a09a10b325e59",
            "e5f86d3d595748d38a070d777d3876b0",
            "1d6bc9ac89bb4e7bba794d93fc5a21b1",
            "b3c8cc2769894b52a3b1b0c8851735e0",
            "d813eae810d142c2842bc7c1c22d2362",
            "312f2dfe8a384706a0a7489a0afd4250",
            "8fc31a28205e41e280546fa1c71fb0e2",
            "2b037e4a31c64985bf349dd20d8d6b09",
            "e81ccbfc321b4aad8af8b5536c558b1c",
            "85afb466ea7f472cbcdb2aca2f345091",
            "35718281b6694016acf14c0669826081"
          ]
        },
        "outputId": "162bbfeb-3af0-46aa-d68d-b6945bcca158"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2053 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb350fa9bcb8461dbe8a09a10b325e59"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the model and move it to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function to generate embeddings for each article\n",
        "def get_embeddings(batch):\n",
        "    with torch.no_grad():\n",
        "        input_ids = torch.tensor(batch['input_ids']).to(device)\n",
        "        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Use the [CLS] token's output as the embedding\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "    return {\"embeddings\": [emb.tolist() for emb in embeddings]}\n",
        "\n",
        "# Apply the function to generate embeddings\n",
        "embedded_data = tokenized_data.map(get_embeddings, batched=True, batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViKB9sRHBPkf"
      },
      "source": [
        "### Task3: Retrieval-Augmented Question Answering\n",
        "1. Implement a simple RAG system where user queries are matched against the knowledge base.\n",
        "2. Retrieve the top 3 most relevant articles and use a generative LLM to answer the query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iQybDB75BPkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684d1313-0fbf-402d-82e4-c774b5c54d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is artificial intelligence?\n",
            "Answer: summarize: The following is a list of mental disorders. This is aList of famous walls. This list of color topics is also called a List of Color Topics. The list of colors is also known as the List of Colour Topics.\n"
          ]
        }
      ],
      "source": [
        "# Create a FAISS index and add embeddings\n",
        "# Get the dimension of the embeddings\n",
        "dimension = len(embedded_data['embeddings'][0])\n",
        "\n",
        "# Create a FAISS index with L2 (Euclidean) distance\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Convert the list of embeddings to a NumPy array and add it to the FAISS index\n",
        "embeddings = np.array([np.array(e) for e in embedded_data['embeddings']])\n",
        "index.add(embeddings)\n",
        "\n",
        "# Load a generative model\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "gen_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n",
        "\n",
        "# Function to retrieve and generate answers\n",
        "def retrieve_and_generate(query):\n",
        "    # Tokenize query and get its embedding\n",
        "    query_token = tokenizer(query, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        query_embedding = model(**query_token).last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Retrieve top 3 articles\n",
        "    _, indices = index.search(query_embedding, 3)\n",
        "    indices = indices[0].astype(int)  # Convert numpy.int64 to int\n",
        "    retrieved_articles = [data[int(i)]['text'] for i in indices]\n",
        "\n",
        "    # Concatenate articles and generate answer\n",
        "    input_text = \" \".join(retrieved_articles)\n",
        "    inputs = gen_tokenizer.encode(\"summarize: \" + input_text, return_tensors='pt', truncation=True).to(device)\n",
        "    summary_ids = gen_model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    answer = gen_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Test with an example query\n",
        "query = \"What is artificial intelligence?\"\n",
        "print(\"Query:\", query)\n",
        "print(\"Answer:\", retrieve_and_generate(query))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai7O4oMlBPki"
      },
      "source": [
        "### Task4:Evaluation\n",
        "1. Evaluate the performance of the system using 5 queries of your choice.\n",
        "2. Analyze the quality of the answers and suggest improvements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "51mEX5mgBPkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4037c4eb-14e6-40df-a26d-ead10a2f10f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is machine learning?\n",
            "Answer: summarize: The following is a list of mental disorders. This is aList of famous walls. This list of color topics is also called a List of Color Topics. The list of colors is also known as the List of Colour Topics.\n",
            "\n",
            "\n",
            "Query: Explain natural language processing.\n",
            "Answer: Cognitive science studies how people make their ideas and what makes thoughts logical. It is often seen as the result of several different scientific fields working together. It does not refer to the sum of all these disciplines. It refers to their intersection on specific problems.\n",
            "\n",
            "\n",
            "Query: What is the capital of France?\n",
            "Answer: The following is a list of mental disorders. The following is an list of famous walls. The list includes famous people, places, and events. For more information on mental disorders, see the Mental Health Atlas.\n",
            "\n",
            "\n",
            "Query: Describe the theory of relativity.\n",
            "Answer: This is a list of elements by atomic number with symbol.summarize: This is a lists of physicists. Quick may refer to: Speed Quick (restaurant chain), a French fast-food chain and an American-made car.\n",
            "\n",
            "\n",
            "Query: What is climate change?\n",
            "Answer: summarize: The following is a list of mental disorders. This is aList of famous walls. This list of color topics is also called a List of Color Topics. The list of colors is also known as the List of Colour Topics.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "queries = [\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain natural language processing.\",\n",
        "    \"What is the capital of France?\",\n",
        "    \"Describe the theory of relativity.\",\n",
        "    \"What is climate change?\"\n",
        "]\n",
        "\n",
        "# Generate and print answers for each query\n",
        "for query in queries:\n",
        "    print(\"Query:\", query)\n",
        "    print(\"Answer:\", retrieve_and_generate(query))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4QaAXxSx71J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb350fa9bcb8461dbe8a09a10b325e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5f86d3d595748d38a070d777d3876b0",
              "IPY_MODEL_1d6bc9ac89bb4e7bba794d93fc5a21b1",
              "IPY_MODEL_b3c8cc2769894b52a3b1b0c8851735e0"
            ],
            "layout": "IPY_MODEL_d813eae810d142c2842bc7c1c22d2362"
          }
        },
        "e5f86d3d595748d38a070d777d3876b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312f2dfe8a384706a0a7489a0afd4250",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc31a28205e41e280546fa1c71fb0e2",
            "value": "Map: 100%"
          }
        },
        "1d6bc9ac89bb4e7bba794d93fc5a21b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b037e4a31c64985bf349dd20d8d6b09",
            "max": 2053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e81ccbfc321b4aad8af8b5536c558b1c",
            "value": 2053
          }
        },
        "b3c8cc2769894b52a3b1b0c8851735e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85afb466ea7f472cbcdb2aca2f345091",
            "placeholder": "​",
            "style": "IPY_MODEL_35718281b6694016acf14c0669826081",
            "value": " 2053/2053 [01:02&lt;00:00, 33.00 examples/s]"
          }
        },
        "d813eae810d142c2842bc7c1c22d2362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "312f2dfe8a384706a0a7489a0afd4250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc31a28205e41e280546fa1c71fb0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b037e4a31c64985bf349dd20d8d6b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81ccbfc321b4aad8af8b5536c558b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85afb466ea7f472cbcdb2aca2f345091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35718281b6694016acf14c0669826081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}